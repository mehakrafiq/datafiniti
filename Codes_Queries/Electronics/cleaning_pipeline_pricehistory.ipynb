{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All keys in the JSON file:\n",
      "rating\n",
      "term\n",
      "warranty\n",
      "sizes\n",
      "quantities\n",
      "upc\n",
      "ean\n",
      "taxonomyLevel2\n",
      "colors\n",
      "country\n",
      "address\n",
      "numHelpful\n",
      "mostRecentPriceAvailability\n",
      "mostRecentPriceCurrency\n",
      "amountMax\n",
      "id\n",
      "monthlyPaymentMax\n",
      "didPurchase\n",
      "taxonomy\n",
      "mostRecentPriceSize\n",
      "merchants\n",
      "lastDateSeen\n",
      "value\n",
      "gtins\n",
      "province\n",
      "amountMin\n",
      "imageURLs\n",
      "brand\n",
      "domains\n",
      "dateAdded\n",
      "username\n",
      "availability\n",
      "sourceURLs\n",
      "doRecommend\n",
      "phone\n",
      "isSale\n",
      "reviews\n",
      "shipping\n",
      "monthlyPaymentMin\n",
      "city\n",
      "size\n",
      "text\n",
      "weight\n",
      "skus\n",
      "name\n",
      "financingAndLeasing\n",
      "firstDateSeen\n",
      "key\n",
      "merchant\n",
      "mostRecentPriceFirstDateSeen\n",
      "ean13\n",
      "offer\n",
      "upca\n",
      "title\n",
      "keys\n",
      "descriptions\n",
      "replace\n",
      "features\n",
      "asins\n",
      "prices\n",
      "postalCode\n",
      "mostRecentPriceDomain\n",
      "date\n",
      "dateUpdated\n",
      "apiURLs\n",
      "categories\n",
      "color\n",
      "manufacturer\n",
      "currency\n",
      "taxonomyLevel4\n",
      "mostRecentPriceAmount\n",
      "taxonomyLevel1\n",
      "taxonomyLevel3\n",
      "primaryImageURLs\n",
      "returnPolicy\n",
      "dateSeen\n",
      "condition\n",
      "dimension\n",
      "websiteIDs\n"
     ]
    }
   ],
   "source": [
    "#Extract all keys from the JSON object\n",
    "\n",
    "# Load the JSON object from the uploaded file\n",
    "file_path = 'Output_JSONs/json_object_1.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Function to recursively extract all keys from the JSON object\n",
    "def extract_keys(obj, keys=set()):\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            keys.add(key)\n",
    "            extract_keys(value, keys)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            extract_keys(item, keys)\n",
    "    return keys\n",
    "\n",
    "# Extract all keys from the JSON data\n",
    "all_keys = extract_keys(json_data)\n",
    "\n",
    "# Print all unique keys\n",
    "print(\"All keys in the JSON file:\")\n",
    "for key in all_keys:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to Extracted_info_prices/0719192625952.json\n",
      "Extracted data saved to Extracted_info_prices/0719192630840.json\n",
      "Extracted data saved to Extracted_info_prices/0719192630833.json\n",
      "Extracted data saved to Extracted_info_prices/0719192630949.json\n",
      "Extracted data saved to Extracted_info_prices/0719192631038.json\n",
      "Extracted data saved to Extracted_info_prices/unknown_ean.json\n",
      "Extracted data saved to Extracted_info_prices/0027242921955.json\n",
      "Extracted data saved to Extracted_info_prices/0719192633056.json\n",
      "Extracted data saved to Extracted_info_prices/0719192631014.json\n",
      "Extracted data saved to Extracted_info_prices/0811635020918.json\n"
     ]
    }
   ],
   "source": [
    "# Define the folder paths\n",
    "input_folder_path = 'Output_JSONs'\n",
    "output_folder_path = 'Extracted_info_prices'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Iterate through all JSON files in the input folder\n",
    "for file_name in os.listdir(input_folder_path):\n",
    "    if file_name.endswith('.json'):  # Process only JSON files\n",
    "        file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "        # Load the JSON object from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "\n",
    "        # Extract the required fields\n",
    "        extracted_data = {\n",
    "            \"ean\": json_data.get(\"ean\"),\n",
    "            \"prices\": json_data.get(\"prices\")\n",
    "            }\n",
    "\n",
    "\n",
    "        # Save the extracted data to a new JSON file named with the EAN number\n",
    "        ean_number = extracted_data[\"ean\"][0] if extracted_data[\"ean\"] else \"unknown_ean\"\n",
    "        output_file_path = os.path.join(output_folder_path, f'{ean_number}.json')\n",
    "        with open(output_file_path, 'w') as outfile:\n",
    "            json.dump(extracted_data, outfile)\n",
    "\n",
    "        print(f'Extracted data saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to Pricing_history/0719192630840.json\n",
      "Extracted data saved to Pricing_history/0719192633056.json\n",
      "Extracted data saved to Pricing_history/0719192630949.json\n",
      "Extracted data saved to Pricing_history/0027242921955.json\n",
      "Extracted data saved to Pricing_history/0719192630833.json\n",
      "Extracted data saved to Pricing_history/0719192631014.json\n",
      "Extracted data saved to Pricing_history/0719192631038.json\n",
      "Extracted data saved to Pricing_history/0811635020918.json\n",
      "Extracted data saved to Pricing_history/0719192625952.json\n"
     ]
    }
   ],
   "source": [
    "# Define the folder paths\n",
    "input_folder_path = 'Extracted_info_prices'\n",
    "output_folder_path = 'Pricing_history'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Helper function to extract the base domain from a URL\n",
    "def get_base_domain(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        return domain\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Helper function to parse ISO format with different variations\n",
    "def parse_iso_date(date_str):\n",
    "    for fmt in (\"%Y-%m-%dT%H:%M:%S.%fZ\", \"%Y-%m-%dT%H:%M:%S.%f\", \"%Y-%m-%dT%H:%M:%SZ\", \"%Y-%m-%dT%H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    raise ValueError(f\"Unknown date format: {date_str}\")\n",
    "\n",
    "# Iterate through all JSON files in the input folder\n",
    "for file_name in os.listdir(input_folder_path):\n",
    "    if file_name == \"unknown_ean.json\":  # Skip files with unknown EAN number\n",
    "        continue\n",
    "    if file_name.endswith('.json'):  # Process only JSON files\n",
    "        file_path = os.path.join(input_folder_path, file_name)\n",
    "        \n",
    "        # Load the JSON object from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        # Dictionary to hold aggregated data\n",
    "        merchant_data = defaultdict(lambda: {\n",
    "            \"amountMax\": float('-inf'),\n",
    "            \"amountMin\": float('inf'),\n",
    "            \"amounts\": defaultdict(list),\n",
    "            \"firstDateSeen\": None,\n",
    "            \"lastDateSeen\": None,\n",
    "            \"sourceURLs\": set()\n",
    "        })\n",
    "\n",
    "        # Iterate through each price entry and aggregate data\n",
    "        for price_entry in json_data.get('prices', []):\n",
    "            merchant = price_entry.get('merchant')\n",
    "            source_urls = price_entry.get('sourceURLs', [])\n",
    "            \n",
    "            if not merchant:\n",
    "                if len(source_urls) == 1:\n",
    "                    merchant = get_base_domain(source_urls[0])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            merchant_key = merchant[:6].lower()\n",
    "\n",
    "            merchant_data[merchant_key][\"amountMax\"] = max(merchant_data[merchant_key][\"amountMax\"], price_entry[\"amountMax\"])\n",
    "            merchant_data[merchant_key][\"amountMin\"] = min(merchant_data[merchant_key][\"amountMin\"], price_entry[\"amountMin\"])\n",
    "            amount = price_entry[\"amountMax\"]\n",
    "            merchant_data[merchant_key][\"amounts\"][amount].extend(price_entry[\"dateSeen\"])\n",
    "            \n",
    "            #first_date_seen = parse_iso_date(price_entry[\"firstDateSeen\"])\n",
    "            try:\n",
    "                first_date_seen = parse_iso_date(price_entry[\"firstDateSeen\"])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    first_date_seen = parse_iso_date(price_entry[\"lastDateSeen\"])\n",
    "                except KeyError:\n",
    "                    first_date_seen = min(parse_iso_date(date) for date in price_entry[\"dateSeen\"])\n",
    "\n",
    "\n",
    "            #last_date_seen = parse_iso_date(price_entry[\"lastDateSeen\"])\n",
    "            try:\n",
    "                last_date_seen = parse_iso_date(price_entry[\"lastDateSeen\"])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    last_date_seen = parse_iso_date(price_entry[\"firstDateSeen\"])\n",
    "                except KeyError:\n",
    "                    last_date_seen = max(parse_iso_date(date) for date in price_entry[\"dateSeen\"])\n",
    "                  \n",
    "    \n",
    "            if not merchant_data[merchant_key][\"firstDateSeen\"] or first_date_seen < merchant_data[merchant_key][\"firstDateSeen\"]:\n",
    "                merchant_data[merchant_key][\"firstDateSeen\"] = first_date_seen\n",
    "            if not merchant_data[merchant_key][\"lastDateSeen\"] or last_date_seen > merchant_data[merchant_key][\"lastDateSeen\"]:\n",
    "                merchant_data[merchant_key][\"lastDateSeen\"] = last_date_seen\n",
    "            \n",
    "            merchant_data[merchant_key][\"sourceURLs\"].update([get_base_domain(url) for url in source_urls if get_base_domain(url)])\n",
    "\n",
    "        # Prepare the final extracted data\n",
    "        final_data = {\n",
    "            \"ean\": json_data.get(\"ean\"),\n",
    "            \"prices\": []\n",
    "        }\n",
    "\n",
    "        for merchant_key, data in merchant_data.items():\n",
    "            price_data = {\n",
    "                \"merchant\": merchant_key,\n",
    "                \"amountMax\": data[\"amountMax\"],\n",
    "                \"amountMin\": data[\"amountMin\"],\n",
    "                \"firstDateSeen\": data[\"firstDateSeen\"].isoformat(),\n",
    "                \"lastDateSeen\": data[\"lastDateSeen\"].isoformat(),\n",
    "                \"sourceURLs\": list(data[\"sourceURLs\"])\n",
    "            }\n",
    "            for i, (amount, dates) in enumerate(data[\"amounts\"].items()):\n",
    "                price_data[f\"currency_{i}\" if i > 0 else \"currency\"] = amount\n",
    "                price_data[f\"dateSeen_{i}\" if i > 0 else \"dateSeen\"] = sorted(dates)\n",
    "            final_data[\"prices\"].append(price_data)\n",
    "\n",
    "        # Save the extracted data to a new JSON file named with the EAN number\n",
    "        ean_number = json_data.get(\"ean\", [\"unknown_ean\"])[0]\n",
    "\n",
    "         # Skip files with unknown EAN number\n",
    "        if ean_number == \"unknown_ean\":\n",
    "            continue\n",
    "\n",
    "        # Save the updated JSON file to the output folder\n",
    "        output_file_path = os.path.join(output_folder_path, f'{ean_number}.json')\n",
    "        with open(output_file_path, 'w') as outfile:\n",
    "            json.dump(final_data, outfile, indent=2)\n",
    "\n",
    "        print(f'Extracted data saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigticket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
