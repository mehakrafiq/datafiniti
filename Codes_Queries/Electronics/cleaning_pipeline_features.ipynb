{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to Extracted_features/0719192625952.json\n",
      "Extracted data saved to Extracted_features/0719192630840.json\n",
      "Extracted data saved to Extracted_features/0719192630833.json\n",
      "Extracted data saved to Extracted_features/0719192630949.json\n",
      "Extracted data saved to Extracted_features/0719192631038.json\n",
      "Extracted data saved to Extracted_features/unknown_ean.json\n",
      "Extracted data saved to Extracted_features/0027242921955.json\n",
      "Extracted data saved to Extracted_features/0719192633056.json\n",
      "Extracted data saved to Extracted_features/0719192631014.json\n",
      "Extracted data saved to Extracted_features/0811635020918.json\n"
     ]
    }
   ],
   "source": [
    "# Define the folder paths\n",
    "input_folder_path = 'Output_JSONs'\n",
    "output_folder_path = 'Extracted_features'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Iterate through all JSON files in the input folder\n",
    "for file_name in os.listdir(input_folder_path):\n",
    "    if file_name.endswith('.json'):  # Process only JSON files\n",
    "        file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "        # Load the JSON object from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        # Extract the required fields\n",
    "        extracted_data = {\n",
    "            \"brand\": json_data.get(\"brand\"),\n",
    "            \"category\": json_data.get(\"categories\"),\n",
    "            \"features\": [\n",
    "                {\n",
    "                    \"key\": feature.get(\"key\"),\n",
    "                    \"value\": feature.get(\"value\")\n",
    "                } for feature in json_data.get(\"features\", [])\n",
    "            ],\n",
    "            \"ean\": json_data.get(\"ean\"),\n",
    "            \"ean13\": json_data.get(\"ean13\"),\n",
    "            \"taxonomy\": json_data.get(\"taxonomy\"),\n",
    "        }\n",
    "\n",
    "        # Save the extracted data to a new JSON file named with the EAN number\n",
    "        ean_number = extracted_data[\"ean\"][0] if extracted_data[\"ean\"] else \"unknown_ean\"\n",
    "        output_file_path = os.path.join(output_folder_path, f'{ean_number}.json')\n",
    "        with open(output_file_path, 'w') as outfile:\n",
    "            json.dump(extracted_data, outfile, indent=2)\n",
    "\n",
    "        print(f'Extracted data saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to key_features/0719192630840.json\n",
      "Updated data saved to key_features/0719192633056.json\n",
      "Updated data saved to key_features/0719192630949.json\n",
      "Updated data saved to key_features/0027242921955.json\n",
      "Updated data saved to key_features/0719192630833.json\n",
      "Updated data saved to key_features/0719192631014.json\n",
      "Updated data saved to key_features/0719192631038.json\n",
      "Updated data saved to key_features/0811635020918.json\n",
      "Updated data saved to key_features/0719192625952.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "# Define the folder paths\n",
    "input_folder_path = 'Extracted_features'\n",
    "output_folder_path = 'key_features'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Function to generate the top 10 feature keys using the Mistral model from Ollama\n",
    "def generate_top_feature_keys(taxonomy):\n",
    "    prompt = f\"Based on the taxonomy '{taxonomy}', define the top 10 feature keys for a product in this category.\"\n",
    "\n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ])\n",
    "\n",
    "    if response and 'message' in response and 'content' in response['message']:\n",
    "        top_features = response['message']['content'].strip().split('\\n')\n",
    "        return list(set([feature.strip() for feature in top_features if feature.strip()]))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to extract feature information using the Mistral model from Ollama\n",
    "def extract_feature_information(features, top_features):\n",
    "    prompt = \"Based on the following top feature keys, find and fill in the information from the given features:\\n\\n\"\n",
    "    for feature in top_features:\n",
    "        prompt += f\"- {feature}\\n\"\n",
    "    prompt += \"\\nFrom the given features:\\n\\n\"\n",
    "    for feature in features:\n",
    "        prompt += f\"- {feature['key']}: {feature['value']}\\n\"\n",
    "\n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ])\n",
    "\n",
    "    if response and 'message' in response and 'content' in response['message']:\n",
    "        filled_features = response['message']['content'].strip().split('\\n')\n",
    "        return filled_features\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Iterate through all JSON files in the input folder\n",
    "for file_name in os.listdir(input_folder_path):\n",
    "    if file_name == \"unknown_ean.json\":  # Skip files with unknown EAN number\n",
    "        continue\n",
    "    if file_name.endswith('.json'):  # Process only JSON files\n",
    "        file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "        # Load the JSON object from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        # Extract the taxonomy\n",
    "        taxonomy = json_data.get(\"taxonomy\", [])\n",
    "        if not taxonomy:\n",
    "            continue\n",
    "        taxonomy = taxonomy[0]\n",
    "\n",
    "        # Check if the top features file exists for this taxonomy\n",
    "        top_features_file = os.path.join(output_folder_path, f'{taxonomy.replace(\" \", \"_\").replace(\">\", \"_\")}_top_features.txt')\n",
    "        if os.path.exists(top_features_file):\n",
    "            # Load the top features from the file\n",
    "            with open(top_features_file, 'r') as file:\n",
    "                top_features = [line.strip() for line in file.readlines()]\n",
    "        else:\n",
    "            # Generate the top 10 feature keys using Mistral\n",
    "            top_features = generate_top_feature_keys(taxonomy)\n",
    "\n",
    "            if top_features:\n",
    "                # Save the top features to a file\n",
    "                with open(top_features_file, 'w') as file:\n",
    "                    for feature in top_features:\n",
    "                        file.write(f'{feature}\\n')\n",
    "\n",
    "        if top_features:\n",
    "            # Extract the features\n",
    "            features = json_data.get(\"features\", [])\n",
    "            \n",
    "            # Use Mistral to fill in the information for the top features\n",
    "            filled_features = extract_feature_information(features, top_features)\n",
    "            \n",
    "            if filled_features:\n",
    "                # Create a dictionary from the filled features\n",
    "                new_features = []\n",
    "                for feature in filled_features:\n",
    "                    if \": \" in feature:\n",
    "                        key, value = feature.split(\": \", 1)\n",
    "                        new_features.append({\"key\": key, \"value\": value})\n",
    "\n",
    "                # Create the new JSON object with the top 10 features\n",
    "                new_json_data = {\n",
    "                    \"brand\": json_data.get(\"brand\"),\n",
    "                    \"category\": json_data.get(\"category\"),\n",
    "                    \"ean\": json_data.get(\"ean\"),\n",
    "                    \"ean13\": json_data.get(\"ean13\"),\n",
    "                    \"features\": new_features\n",
    "                }\n",
    "\n",
    "                # Save the new JSON file to the output folder\n",
    "                output_file_path = os.path.join(output_folder_path, file_name)\n",
    "                with open(output_file_path, 'w') as outfile:\n",
    "                    json.dump(new_json_data, outfile, indent=4)\n",
    "\n",
    "                print(f'Updated data saved to {output_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigticket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
